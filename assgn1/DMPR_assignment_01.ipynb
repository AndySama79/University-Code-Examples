{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78f24930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import timeit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaf9a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('read_time.csv','w',newline='') as f1:\n",
    "    writer = csv.writer(f1)\n",
    "    writer.writerow(['format','time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ccc66d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('write_time.csv','w',newline='') as f2:\n",
    "    writer = csv.writer(f2)\n",
    "    writer.writerow(['format','time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b08f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('size.csv','w',newline='') as f3:\n",
    "    writer = csv.writer(f3)\n",
    "    writer.writerow(['format','time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89a2063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('vehicles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf0bccf",
   "metadata": {},
   "source": [
    "# .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c73e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = ''\n",
    "fname = 'vehicles.csv'\n",
    "\n",
    "t_csv_read = timeit.timeit('pd.read_csv(os.path.join(datadir,fname))', number=3, globals=globals())\n",
    "t_csv_write = timeit.timeit('df.to_csv(\"vehicles.csv\")', number=3, globals=globals())\n",
    "t_csv_size = os.path.getsize(fname)\n",
    "\n",
    "with open('read_time.csv','a',newline='') as f1:\n",
    "    writer = csv.writer(f1)\n",
    "    writer.writerow(['csv',t_csv_read])\n",
    "    \n",
    "with open('write_time.csv','a',newline='') as f2:\n",
    "    writer = csv.writer(f2)\n",
    "    writer.writerow(['csv',t_csv_write])\n",
    " \n",
    "with open('size.csv','a',newline='') as f3:\n",
    "    writer = csv.writer(f3)\n",
    "    writer.writerow(['csv',t_csv_size])\n",
    "\n",
    "    \n",
    "print(t_csv_read,t_csv_write,t_csv_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6d64c2",
   "metadata": {},
   "source": [
    "## .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d5c1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = ''\n",
    "fname = 'vehicles.json'\n",
    "\n",
    "t_json_read = timeit.timeit('pd.read_json(os.path.join(datadir,fname))', number=3, globals=globals())\n",
    "t_json_write = timeit.timeit('df.to_json(\"vehicles.json\")', number=3, globals=globals())\n",
    "t_json_size = os.path.getsize(fname)\n",
    "\n",
    "with open('read_time.csv','a',newline='') as f1:\n",
    "    writer = csv.writer(f1)\n",
    "    writer.writerow(['json',t_json_read])\n",
    "    \n",
    "with open('write_time.csv','a',newline='') as f2:\n",
    "    writer = csv.writer(f2)\n",
    "    writer.writerow(['json',t_json_write])\n",
    " \n",
    "with open('size.csv','a',newline='') as f3:\n",
    "    writer = csv.writer(f3)\n",
    "    writer.writerow(['json',t_json_size])\n",
    "\n",
    "    \n",
    "print(t_json_read,t_json_write,t_json_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63cb6a7",
   "metadata": {},
   "source": [
    "# .pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7efca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = ''\n",
    "fname = 'vehicles.pickle'\n",
    "\n",
    "t_pickle_read = timeit.timeit('pd.read_pickle(os.path.join(datadir,fname))', number=3, globals=globals())\n",
    "t_pickle_write = timeit.timeit('df.to_pickle(\"vehicles.pickle\")', number=3, globals=globals())\n",
    "t_pickle_size = os.path.getsize(fname)\n",
    "\n",
    "with open('read_time.csv','a',newline='') as f1:\n",
    "    writer = csv.writer(f1)\n",
    "    writer.writerow(['pickle',t_pickle_read])\n",
    "    \n",
    "with open('write_time.csv','a',newline='') as f2:\n",
    "    writer = csv.writer(f2)\n",
    "    writer.writerow(['pickle',t_pickle_write])\n",
    " \n",
    "with open('size.csv','a',newline='') as f3:\n",
    "    writer = csv.writer(f3)\n",
    "    writer.writerow(['pickle',t_pickle_size])\n",
    "\n",
    "    \n",
    "print(t_pickle_read,t_pickle_write,t_pickle_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fb9c79",
   "metadata": {},
   "source": [
    "# .parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd66316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = ''\n",
    "fname = 'vehicles.parquet'\n",
    "\n",
    "t_parquet_read = timeit.timeit('pd.read_parquet(os.path.join(datadir,fname))', number=3, globals=globals())\n",
    "t_parquet_write = timeit.timeit('df.to_parquet(\"vehicles.parquet\")', number=3, globals=globals())\n",
    "t_parquet_size = os.path.getsize(fname)\n",
    "\n",
    "with open('read_time.csv','a',newline='') as f1:\n",
    "    writer = csv.writer(f1)\n",
    "    writer.writerow(['parquet',t_parquet_read])\n",
    "    \n",
    "with open('write_time.csv','a',newline='') as f2:\n",
    "    writer = csv.writer(f2)\n",
    "    writer.writerow(['parquet',t_parquet_write])\n",
    " \n",
    "with open('size.csv','a',newline='') as f3:\n",
    "    writer = csv.writer(f3)\n",
    "    writer.writerow(['parquet',t_parquet_size])\n",
    "\n",
    "    \n",
    "print(t_parquet_read,t_parquet_write,t_parquet_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af9a941",
   "metadata": {},
   "source": [
    "# .feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9c3213",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = ''\n",
    "fname = 'vehicles.feather'\n",
    "\n",
    "t_feather_read = timeit.timeit('pd.read_feather(os.path.join(datadir,fname))', number=3, globals=globals())\n",
    "t_feather_write = timeit.timeit('df.to_feather(\"vehicles.feather\")', number=3, globals=globals())\n",
    "t_feather_size = os.path.getsize(fname)\n",
    "\n",
    "with open('read_time.csv','a',newline='') as f1:\n",
    "    writer = csv.writer(f1)\n",
    "    writer.writerow(['feather',t_feather_read])\n",
    "    \n",
    "with open('write_time.csv','a',newline='') as f2:\n",
    "    writer = csv.writer(f2)\n",
    "    writer.writerow(['feather',t_feather_write])\n",
    " \n",
    "with open('size.csv','a',newline='') as f3:\n",
    "    writer = csv.writer(f3)\n",
    "    writer.writerow(['feather',t_feather_size])\n",
    "\n",
    "    \n",
    "print(t_feather_read,t_feather_write,t_feather_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223a1e0f",
   "metadata": {},
   "source": [
    "# .hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1fa06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = ''\n",
    "fname = 'vehicles.h5'\n",
    "\n",
    "t_hdf_read = timeit.timeit('pd.read_hdf(os.path.join(datadir,fname))', number=3, globals=globals())\n",
    "t_hdf_write = timeit.timeit('df.to_hdf(\"vehicles.h5\",key = \"df\")', number=3, globals=globals())\n",
    "t_hdf_size = os.path.getsize(fname)\n",
    "\n",
    "with open('read_time.csv','a',newline='') as f1:\n",
    "    writer = csv.writer(f1)\n",
    "    writer.writerow(['hdf',t_hdf_read])\n",
    "    \n",
    "with open('write_time.csv','a',newline='') as f2:\n",
    "    writer = csv.writer(f2)\n",
    "    writer.writerow(['hdf',t_hdf_write])\n",
    " \n",
    "with open('size.csv','a',newline='') as f3:\n",
    "    writer = csv.writer(f3)\n",
    "    writer.writerow(['hdf',t_hdf_size])\n",
    "\n",
    "    \n",
    "print(t_hdf_read,t_hdf_write,t_hdf_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52a9205",
   "metadata": {},
   "source": [
    "# .xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd55f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = ''\n",
    "fname = 'vehicles.xml'\n",
    "\n",
    "t_feather_read = timeit.timeit('pd.read_xml(os.path.join(datadir,fname))', number=3, globals=globals())\n",
    "t_feather_write = timeit.timeit('df.to_xml(\"vehicles.xml\")', number=3, globals=globals())\n",
    "t_feather_size = os.path.getsize(fname)\n",
    "\n",
    "with open('read_time.csv','a',newline='') as f1:\n",
    "    writer = csv.writer(f1)\n",
    "    writer.writerow(['xml',t_xml_read])\n",
    "    \n",
    "with open('write_time.csv','a',newline='') as f2:\n",
    "    writer = csv.writer(f2)\n",
    "    writer.writerow(['xml',t_xml_write])\n",
    " \n",
    "with open('size.csv','a',newline='') as f3:\n",
    "    writer = csv.writer(f3)\n",
    "    writer.writerow(['xml',t_xml_size])\n",
    "\n",
    "    \n",
    "print(t_xml_read,t_xml_write,t_xml_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e644589",
   "metadata": {},
   "source": [
    "# .excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd210f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = ''\n",
    "fname = 'vehicles.xlsx'\n",
    "\n",
    "t_xlsx_read = timeit.timeit('pd.read_xlsx(os.path.join(datadir,fname))', number=3, globals=globals())\n",
    "t_xlsx_write = timeit.timeit('df.to_xlsx(\"vehicles.xlsx\")', number=3, globals=globals())\n",
    "t_xlsx_size = os.path.getsize(fname)\n",
    "\n",
    "with open('read_time.csv','a',newline='') as f1:\n",
    "    writer = csv.writer(f1)\n",
    "    writer.writerow(['xlsx',t_xlsx_read])\n",
    "    \n",
    "with open('write_time.csv','a',newline='') as f2:\n",
    "    writer = csv.writer(f2)\n",
    "    writer.writerow(['xlsx',t_xlsx_write])\n",
    " \n",
    "with open('size.csv','a',newline='') as f3:\n",
    "    writer = csv.writer(f3)\n",
    "    writer.writerow(['xlsx',t_xlsx_size])\n",
    "\n",
    "    \n",
    "print(t_xlsx_read,t_xlsx_write,t_xlsx_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7547de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4c2c7933b6c685c9a4a219b054fda9c434dbbacc5a17473fda40716404ebaaf7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
