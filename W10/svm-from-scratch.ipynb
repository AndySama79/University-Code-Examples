{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030524,
     "end_time": "2021-02-05T08:35:20.644765",
     "exception": false,
     "start_time": "2021-02-05T08:35:20.614241",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-02-05T08:35:20.707108Z",
     "iopub.status.busy": "2021-02-05T08:35:20.706255Z",
     "iopub.status.idle": "2021-02-05T08:35:22.030285Z",
     "shell.execute_reply": "2021-02-05T08:35:22.029304Z"
    },
    "papermill": {
     "duration": 1.356956,
     "end_time": "2021-02-05T08:35:22.030572",
     "exception": false,
     "start_time": "2021-02-05T08:35:20.673616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs, make_moons, make_circles\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030033,
     "end_time": "2021-02-05T08:35:22.090061",
     "exception": false,
     "start_time": "2021-02-05T08:35:22.060028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Creating three types of datasets using make_blobs ([docmentation](https://scikit-learn.org/stable/auto_examples/cluster/plot_linkage_comparison.html#sphx-glr-auto-examples-cluster-plot-linkage-comparison-py)). \n",
    "\n",
    "1. Using make_blobs\n",
    "2. Using make_moons\n",
    "3. Using make_circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T08:35:22.158512Z",
     "iopub.status.busy": "2021-02-05T08:35:22.157662Z",
     "iopub.status.idle": "2021-02-05T08:35:22.526726Z",
     "shell.execute_reply": "2021-02-05T08:35:22.525962Z"
    },
    "papermill": {
     "duration": 0.405485,
     "end_time": "2021-02-05T08:35:22.526915",
     "exception": false,
     "start_time": "2021-02-05T08:35:22.121430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X1, y1 = make_blobs(n_samples=200, centers=2,random_state=0, cluster_std=0.60)\n",
    "y1 = np.where(y1 <= 0, -1, 1)\n",
    "print(\"First five rows and col values \\nX1 : \\n\",X1[:5], \" \\n y1 :\\n\",y1[:5])\n",
    "plt.scatter(X1[:, 0], X1[:, 1], c=y1, s=50, cmap='winter', alpha=.5)\n",
    "plt.title(\"Dataset 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T08:35:22.632140Z",
     "iopub.status.busy": "2021-02-05T08:35:22.630963Z",
     "iopub.status.idle": "2021-02-05T08:35:22.789955Z",
     "shell.execute_reply": "2021-02-05T08:35:22.790596Z"
    },
    "papermill": {
     "duration": 0.220981,
     "end_time": "2021-02-05T08:35:22.790809",
     "exception": false,
     "start_time": "2021-02-05T08:35:22.569828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X2, y2 = make_moons(n_samples=200, noise=.05)\n",
    "y2 = np.where(y2 <= 0, -1, 1)\n",
    "print(\"First five rows and col values \\nX2 : \\n\",X2[:5], \" \\n y2 :\\n\",y1[:5])\n",
    "plt.scatter(X2[:, 0], X2[:, 1], c=y2, s=50, cmap='winter', alpha=.5)\n",
    "plt.title(\"Dataset 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T08:35:22.854640Z",
     "iopub.status.busy": "2021-02-05T08:35:22.853402Z",
     "iopub.status.idle": "2021-02-05T08:35:23.004985Z",
     "shell.execute_reply": "2021-02-05T08:35:23.005595Z"
    },
    "papermill": {
     "duration": 0.185069,
     "end_time": "2021-02-05T08:35:23.005786",
     "exception": false,
     "start_time": "2021-02-05T08:35:22.820717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X3, y3 = noisy_circles = make_circles(n_samples=200, factor=.5, noise=.05)\n",
    "y3 = np.where(y3 <= 0, -1, 1)\n",
    "print(\"First five rows and col values \\nX1 : \\n\",X3[:5], \" \\n y3 :\\n\",y1[:5])\n",
    "plt.scatter(X3[:, 0], X3[:, 1], c=y3, s=50, cmap='winter', alpha=.5)\n",
    "plt.title(\"Dataset 3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024539,
     "end_time": "2021-02-05T08:35:23.056989",
     "exception": false,
     "start_time": "2021-02-05T08:35:23.032450",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<hr>\n",
    "<br>\n",
    "<br>\n",
    "<center><h1> Creating SVM models </h1></center>\n",
    "<br><br><br>\n",
    "\n",
    "## Without kernals\n",
    "\n",
    "For a n-dimensional feature, SVM creates an n-1 dimensional hyperplane to seperate the classes.\n",
    "Any hyperplane can be represented as:\n",
    "\n",
    "<mark> w<sup>T</sup>X -b = 0 </mark>\n",
    "\n",
    "For example, if we have a dataset which can be represented by a line, hyperplane would be a point. In our case we have 2 independent and 1 dependent feature. Thus, our hyperplane is a line with the quation: \n",
    "\n",
    "<mark> y = w<sub>1</sub>X<sub>1</sub> + w<sub>2</sub>X<sub>2</sub> - b </mark>\n",
    "\n",
    "where, w = [ w<sub>1</sub>, w<sub>2</sub> ]\n",
    "\n",
    "We will proceed with the assumption that m<sub>1</sub>, m<sub>2</sub> and b are 0s, and we will update their value in accordane with learning rate. \n",
    "\n",
    "### Hard margin\n",
    "\n",
    "If the dataset can be linearly sperated like our first dataset and partially in the second, we can create two parallel hyperplane(lines here) for each classes and contain each data points under these hyperplanes and our goal would be to maximize the distance between these two parallel hyperplane. The region between these two plane is called **margin**. The equations for both hyperplane is:\n",
    "\n",
    "<mark>\n",
    "w<sup>T</sup>X -b = -1 and,<br> \n",
    "w<sup>T</sup>X -b = 1 \n",
    "</mark>\n",
    "\n",
    "The distance between them is 2/||w|| and to maximize the distance, ||w|| should be minimum. \n",
    "\n",
    "To prevent any data point falling inside margin we add the restriction,\n",
    "\n",
    "<mark>\n",
    "y<sub>i</sub>(w<sup>T</sup>X<sub>i</sub> -b) >= 1 \n",
    "</mark>\n",
    "\n",
    "where y<sub>i</sub> = ith row in the target\n",
    "and X<sub>i</sub> = ith row in the X\n",
    "\n",
    "\n",
    "### Soft margin\n",
    "\n",
    "If the dataset in non-linearly seprable (dataset 2 and 3, **note**: if in dataset 1, one or more points are in wrong classes, then it is also non linear), we can use hinge loss for loss function: <br>\n",
    "\n",
    "<mark> max(0, 1-y<sub>i</sub>(w<sup>T</sup>X<sub>i</sub> -b)), </mark>\n",
    "\n",
    "If the datapoint has class = 1, then the loss will be 0, otherwise it will be the distance between the margin and the datapoint.\n",
    "\n",
    "and our goal is to minimize\n",
    "\n",
    "<mark>Loss = (1/n) Œ£ max(0, 1-y<sub>i</sub>(w<sup>T</sup>X<sub>i</sub> -b)) + Œª||w||<sup>2</sup> </mark>\n",
    "\n",
    "where Œª is a tradeoff between the margin size and x<sub>i</sub> being on the correct side of margon. If Œª is too low, the equation becomes hard margin. \n",
    "\n",
    "<h4>Updating weights</h4>\n",
    "\n",
    "Let's define by how we are updating weights by differntiating both terms in the loss with w<sub>k</sub>:\n",
    "\n",
    "First term:\n",
    "\n",
    "<mark>ùõømax(0, 1-y<sub>i</sub>(w<sup>T</sup>X<sub>i</sub> -b ))/ùõøw<sub>k</sub> = { 0, if y<sub>i</sub>x<sub>i</sub>w -b‚â•1 else -y<sub>i</sub>x<sub>i</sub> }</mark>\n",
    "\n",
    "Second term:\n",
    "\n",
    "<mark>ùõø(Œª||w||<sup>2</sup>)/ùõøw<sub>k</sub> = 2Œªw</mark>\n",
    "\n",
    "If y<sub>i</sub>x<sub>i</sub>w-b‚â•1\n",
    "\n",
    "<mark>w = w - Œ±* 2Œªw</mark>\n",
    "\n",
    "else,\n",
    "\n",
    "<mark>w = w + Œ±* (2Œªw - y<sub>i</sub>x<sub>i</sub>)</mark>\n",
    "\n",
    "<h4>Updating intercept</h4>\n",
    "\n",
    "Differentiaite loss by b\n",
    "\n",
    "First term:\n",
    "\n",
    "<mark>ùõømax(0, 1-y<sub>i</sub>(w<sup>T</sup>X<sub>i</sub> -b ))/ùõøb = { 0, if y<sub>i</sub>x<sub>i</sub>w -b‚â•1 else -y<sub>i</sub> }</mark>\n",
    "\n",
    "Second term:\n",
    "\n",
    "<mark>ùõø(Œª||w||<sup>2</sup>)/ùõøb = 0</mark>\n",
    "\n",
    "\n",
    "If y<sub>i</sub>x<sub>i</sub>w-b‚â•1\n",
    "\n",
    "<mark>b = b + Œ±*0</mark>\n",
    "\n",
    "else,\n",
    "\n",
    "<mark> b = b - Œ±* (y<sub>i</sub>) </mark>\n",
    "\n",
    "\n",
    "**Note**:\n",
    "\n",
    "<h4>Slack Variable</h4>\n",
    "\n",
    "Sometimes we have to allow few points to be inside margin. Slack veriable defines how much we can violate the margin which means how many points can be inside the margin.\n",
    "\n",
    "<mark>\n",
    "y<sub>i</sub>(w<sup>T</sup>X<sub>i</sub> -b) >= 1 - Œæ<sub>i</sub>\n",
    "</mark>\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**References**: \n",
    "\n",
    "1. [Support-vector machine, wikipedia](https://en.wikipedia.org/wiki/Support-vector_machine) \n",
    "2. [Support Vector Machine ‚Äî Introduction to Machine Learning Algorithms, Medium](https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47). \n",
    "3. [A Support Vector Machine in just a few Lines of Python Code](https://maviccprp.github.io/a-support-vector-machine-in-just-a-few-lines-of-python-code/)\n",
    "\n",
    "Please go through these if have facing any difficuly in understanding the implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T08:35:23.120047Z",
     "iopub.status.busy": "2021-02-05T08:35:23.116044Z",
     "iopub.status.idle": "2021-02-05T08:35:23.127245Z",
     "shell.execute_reply": "2021-02-05T08:35:23.125365Z"
    },
    "papermill": {
     "duration": 0.045347,
     "end_time": "2021-02-05T08:35:23.127428",
     "exception": false,
     "start_time": "2021-02-05T08:35:23.082081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SVM_soft_margin:\n",
    "\n",
    "    def __init__(self, alpha = 0.001, lambda_ = 0.01, n_iterations = 1000):\n",
    "        self.alpha = alpha # learning rate\n",
    "        self.lambda_ = lambda_ # tradeoff\n",
    "        self.n_iterations = n_iterations # number of iterations\n",
    "        self.w = None # weights or slopes\n",
    "        self.b = None # intercept\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        n_samples, n_features = X.shape        \n",
    "        self.w = np.zeros(n_features) # initalizing with 0\n",
    "        self.b = 0 # initializewith 0\n",
    "        \n",
    "        for iteration in range(self.n_iterations):\n",
    "            for i, Xi in enumerate(X):\n",
    "                # yixiw-b‚â•1\n",
    "                    ### ENTER YOUR CODE ###\n",
    "                    # w = w + Œ±* (2Œªw - yixi)\n",
    "                    ### ENTER YOUR CODE ###\n",
    "                else:\n",
    "                    # w = w + Œ±* (2Œªw - yixi)\n",
    "                    ### ENTER YOUR CODE ###\n",
    "                    # b = b - Œ±* (yi)\n",
    "                    ### ENTER YOUR CODE ###\n",
    "        return self.w, self.b\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = np.dot(X, self.w) - self.b \n",
    "        # returning in the form of -1 and 1\n",
    "        ### ENTER YOUR CODE ###\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T08:35:23.189594Z",
     "iopub.status.busy": "2021-02-05T08:35:23.188726Z",
     "iopub.status.idle": "2021-02-05T08:35:23.193456Z",
     "shell.execute_reply": "2021-02-05T08:35:23.192695Z"
    },
    "papermill": {
     "duration": 0.036882,
     "end_time": "2021-02-05T08:35:23.193628",
     "exception": false,
     "start_time": "2021-02-05T08:35:23.156746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_hyperplane(x, w, b, offset):\n",
    "        ### ENTER YOUR CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T08:35:23.262013Z",
     "iopub.status.busy": "2021-02-05T08:35:23.256190Z",
     "iopub.status.idle": "2021-02-05T08:35:23.267332Z",
     "shell.execute_reply": "2021-02-05T08:35:23.266635Z"
    },
    "papermill": {
     "duration": 0.047446,
     "end_time": "2021-02-05T08:35:23.267477",
     "exception": false,
     "start_time": "2021-02-05T08:35:23.220031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_svm(X, y, w, b, title ='Plot for linear SVM'):    \n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    plt.scatter(X[:,0], X[:,1], marker='o',c=y)\n",
    "\n",
    "    x0_1 = np.amin(X[:,0])\n",
    "    x0_2 = np.amax(X[:,0])\n",
    "\n",
    "    x1_1 = get_hyperplane(x0_1, w, b, 0)\n",
    "    x1_2 = get_hyperplane(x0_2, w, b, 0)\n",
    "\n",
    "    x1_1_m = get_hyperplane(x0_1, w, b, -1)\n",
    "    x1_2_m = get_hyperplane(x0_2, w, b, -1)\n",
    "\n",
    "    x1_1_p = get_hyperplane(x0_1, w, b, 1)\n",
    "    x1_2_p = get_hyperplane(x0_2, w, b, 1)\n",
    "\n",
    "    ax.plot([x0_1, x0_2],[x1_1, x1_2], 'y--')\n",
    "    ax.plot([x0_1, x0_2],[x1_1_m, x1_2_m], 'k')\n",
    "    ax.plot([x0_1, x0_2],[x1_1_p, x1_2_p], 'k')\n",
    "\n",
    "    x1_min = np.amin(X[:,1])\n",
    "    x1_max = np.amax(X[:,1])\n",
    "    ax.set_ylim([x1_min-3,x1_max+3])\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027815,
     "end_time": "2021-02-05T08:35:23.320902",
     "exception": false,
     "start_time": "2021-02-05T08:35:23.293087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Note** : I am using accuracy_score as we are dealing with classification problems.\n",
    "r2_score is used for regression analysis (used in the Linear regression notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T08:35:23.382230Z",
     "iopub.status.busy": "2021-02-05T08:35:23.381568Z",
     "iopub.status.idle": "2021-02-05T08:35:26.761033Z",
     "shell.execute_reply": "2021-02-05T08:35:26.760403Z"
    },
    "papermill": {
     "duration": 3.413429,
     "end_time": "2021-02-05T08:35:26.761191",
     "exception": false,
     "start_time": "2021-02-05T08:35:23.347762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm1 = SVM_soft_margin()\n",
    "w1,b1 = svm1.fit(X1,y1)\n",
    "print(\"For dataset 1, score:\" ,accuracy_score(svm1.predict(X1),y1))\n",
    "plot_svm(X1, y1, w1, b1, title= 'Linear SVM for dataset 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T08:35:26.834768Z",
     "iopub.status.busy": "2021-02-05T08:35:26.834062Z",
     "iopub.status.idle": "2021-02-05T08:35:30.929778Z",
     "shell.execute_reply": "2021-02-05T08:35:30.928718Z"
    },
    "papermill": {
     "duration": 4.139527,
     "end_time": "2021-02-05T08:35:30.929989",
     "exception": false,
     "start_time": "2021-02-05T08:35:26.790462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm2 = SVM_soft_margin()\n",
    "w2,b2 = svm2.fit(X2,y2)\n",
    "print(\"For dataset 2, score:\" ,accuracy_score(svm2.predict(X2),y2))\n",
    "plot_svm(X2, y2, w2, b2, title= 'Linear SVM for dataset 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T08:35:31.020093Z",
     "iopub.status.busy": "2021-02-05T08:35:31.019193Z",
     "iopub.status.idle": "2021-02-05T08:35:36.541032Z",
     "shell.execute_reply": "2021-02-05T08:35:36.541915Z"
    },
    "papermill": {
     "duration": 5.570674,
     "end_time": "2021-02-05T08:35:36.542132",
     "exception": false,
     "start_time": "2021-02-05T08:35:30.971458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm3 = SVM_soft_margin()\n",
    "w3,b3 = svm3.fit(X3,y3)\n",
    "print(\"For dataset 3, score:\" ,accuracy_score(svm3.predict(X3),y3))\n",
    "plot_svm(X3, y3, w3, b3, title= 'Linear SVM for dataset 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.031005,
     "end_time": "2021-02-05T08:35:37.391795",
     "exception": false,
     "start_time": "2021-02-05T08:35:37.360790",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<br><br>\n",
    "<hr>\n",
    "<br><br>\n",
    "<center><h2>SVM for Non-Linear Dataset using Kernal</h2><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030953,
     "end_time": "2021-02-05T08:35:37.454033",
     "exception": false,
     "start_time": "2021-02-05T08:35:37.423080",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To use SVM for Non-Linear dataset, we have to develop a dual SVM. The maths behind it is a bit complicated so please refer the links below in the order:\n",
    "\n",
    "1. [Support Vector Machines for Beginners ‚Äì Duality Problem](http://www.adeveloperdiary.com/data-science/machine-learning/support-vector-machines-for-beginners-duality-problem/)\n",
    "2. [Support Vector Machines for Beginners ‚Äì Kernel SVM](http://www.adeveloperdiary.com/data-science/machine-learning/support-vector-machines-for-beginners-kernel-svm/)\n",
    "3. [Support Vector Machines for Beginners ‚Äì Training Algorithms](http://www.adeveloperdiary.com/data-science/machine-learning/support-vector-machines-for-beginners-training-algorithms/)\n",
    "\n",
    "<h4>Loss</h4>\n",
    "The Dual Lagrangian loss function which we are trying to maximize is:\n",
    "\n",
    "<mark>L<sub>dual</sub> = ‚àëŒ±<sub>i</sub> ‚Äì (1/2) ‚àë<sub>i</sub> ‚àë<sub>j</sub> Œ±<sub>i</sub> Œ±<sub>j</sub> y<sub>i</sub> y<sub>j</sub> K(x<sub>i</sub>, x<sub>j</sub>) </mark>\n",
    "\n",
    "<h4>Gradient</h4>\n",
    "\n",
    "Differentiating the loss wrt Œ±<sub>k</sub> , using kth term for Gradient Ascent:\n",
    "\n",
    "<mark>Œ¥L<sub>dual</sub>/Œ¥Œ±<sub>k</sub> = 1 ‚Äì y<sub>k</sub> ‚àë Œ±<sub>j</sub> y<sub>j</sub> K(x<sub>j</sub>, x<sub>k</sub>)</mark>\n",
    "\n",
    "where, <br>\n",
    "\n",
    "K(x<sub>i</sub>, x<sub>j</sub>) is our Kernal function which could be linear, polynomial or gaussian(rbf).\n",
    "\n",
    "<h4>Updates</h4>\n",
    "\n",
    "Œ± = Œ± + Œ∑*(gradient)\n",
    "\n",
    "where Œ∑ = learning rate\n",
    "\n",
    "After training, calculate intercept b:\n",
    "\n",
    "<mark>b = avg<sub>C‚â§Œ±i‚â§0</sub>{ y<sub>i</sub> ‚Äì ‚àëŒ±<sub>j</sub>y<sub>j</sub> K(x<sub>j</sub>, x<sub>i</sub>) }</mark>\n",
    "\n",
    "<h4>Prediction </h4>\n",
    "\n",
    "For Œ±>0 :\n",
    "\n",
    "<mark>y^ = sign( ‚àë Œ±<sub>i</sub>y<sub>i</sub> k(x<sub>i</sub>, x<sub>i</sub>)+b)</mark>\n",
    "\n",
    "1. Polynomial = (c + X.y)<sup>degree</sup>\n",
    "\n",
    "2. Gaussian = e <sup> -(1/ œÉ<sup>2</sup>) ||X-y|| <sup>2</sup> </sup> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T08:35:37.537358Z",
     "iopub.status.busy": "2021-02-05T08:35:37.526413Z",
     "iopub.status.idle": "2021-02-05T08:35:37.547045Z",
     "shell.execute_reply": "2021-02-05T08:35:37.546154Z"
    },
    "papermill": {
     "duration": 0.061938,
     "end_time": "2021-02-05T08:35:37.547233",
     "exception": false,
     "start_time": "2021-02-05T08:35:37.485295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SVM_Dual:\n",
    "\n",
    "    def __init__(self, kernel='poly', degree=2, sigma=0.1, epoches=1000, learning_rate= 0.001):\n",
    "        self.alpha = None\n",
    "        self.b = 0\n",
    "        self.degree = degree\n",
    "        self.c = 1\n",
    "        self.C = 1\n",
    "        self.sigma = sigma\n",
    "        self.epoches = epoches\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        if kernel == 'poly':\n",
    "            self.kernel = self.polynomial_kernal # for polynomial kernal\n",
    "        elif kernel == 'rbf':\n",
    "            self.kernel =  self.gaussian_kernal # for guassian\n",
    "\n",
    "    def polynomial_kernal(self,X,Z):\n",
    "        #(c + X.y)^degree\n",
    "        ### ENTER YOUR CODE ###\n",
    "        \n",
    "    def gaussian_kernal(self, X,Z):\n",
    "        #e ^-(1/ œÉ2) ||X-y|| ^2\n",
    "        ### ENTER YOUR CODE ###\n",
    "    \n",
    "    def train(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.alpha = np.random.random(X.shape[0])\n",
    "        self.b = 0\n",
    "        self.ones = np.ones(X.shape[0]) \n",
    "\n",
    "        ### ENTER YOUR CODE #### yi yj K(xi, xj)\n",
    "        ### ENTER YOUR CODE ###\n",
    "\n",
    "        for i in range(self.epoches):\n",
    "            # 1 ‚Äì yk ‚àë Œ±j yj K(xj, xk)\n",
    "            # Œ± = Œ± + Œ∑*(1 ‚Äì yk ‚àë Œ±j yj K(xj, xk)) to maximize\n",
    "            # 0<Œ±<C\n",
    "            # 0<Œ±<C\n",
    "            # loss: ‚àëŒ±i ‚Äì (1/2) ‚àëi ‚àëj Œ±i Œ±j yi yj K(xi, xj)\n",
    "            ### ENTER YOUR CODE ###\n",
    "            \n",
    "        alpha_index = np.where((self.alpha) > 0 & (self.alpha < self.C))[0]\n",
    "        \n",
    "        # for intercept b, we will only consider Œ± which are 0<Œ±<C \n",
    "        b_list = []        \n",
    "        # avgC‚â§Œ±i‚â§0{ yi ‚Äì ‚àëŒ±jyj K(xj, xi) }\n",
    "        ### ENTER YOUR CODE ###\n",
    "            \n",
    "    def predict(self, X):\n",
    "        return np.sign(self.decision_function(X))\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_hat = self.predict(X)\n",
    "        return np.mean(y == y_hat)\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        return (self.alpha * self.y).dot(self.kernel(self.X, X)) + self.b\n",
    "\n",
    "    # https://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane.html\n",
    "    def plot(self, title='Plot for non linear SVM'):\n",
    "        plt.scatter(self.X[:, 0], self.X[:, 1], c=self.y, s=50, cmap='winter', alpha=.5)\n",
    "        ax = plt.gca()\n",
    "        xlim = ax.get_xlim()\n",
    "        ylim = ax.get_ylim()\n",
    "        xx = np.linspace(xlim[0], xlim[1], 50)\n",
    "        yy = np.linspace(ylim[0], ylim[1], 50)\n",
    "        YY, XX = np.meshgrid(yy, xx)\n",
    "        xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "        Z = self.decision_function(xy).reshape(XX.shape)\n",
    "        ax.contour(XX, YY, Z, levels=[-1, 0, 1],linestyles=['--', '-', '--'])\n",
    "        plt.title(title)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T08:35:37.643671Z",
     "iopub.status.busy": "2021-02-05T08:35:37.642208Z",
     "iopub.status.idle": "2021-02-05T08:35:38.057728Z",
     "shell.execute_reply": "2021-02-05T08:35:38.056891Z"
    },
    "papermill": {
     "duration": 0.465773,
     "end_time": "2021-02-05T08:35:38.057888",
     "exception": false,
     "start_time": "2021-02-05T08:35:37.592115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dataset 1, using gaussian\n",
    "svm_dual1 = SVM_Dual(kernel = 'rbf')\n",
    "svm_dual1.train(X1,y1)\n",
    "print(\"Accuracy: \", svm_dual1.score(X1,y1))\n",
    "svm_dual1.plot('Non linear SVM plot for Dataset 1 usign rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T08:35:38.134459Z",
     "iopub.status.busy": "2021-02-05T08:35:38.133619Z",
     "iopub.status.idle": "2021-02-05T08:35:38.526999Z",
     "shell.execute_reply": "2021-02-05T08:35:38.526094Z"
    },
    "papermill": {
     "duration": 0.43447,
     "end_time": "2021-02-05T08:35:38.527175",
     "exception": false,
     "start_time": "2021-02-05T08:35:38.092705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dataset 2, using gaussian\n",
    "svm_dual2 = SVM_Dual(kernel = 'rbf')\n",
    "svm_dual2.train(X2,y2)\n",
    "print(\"Accuracy: \", svm_dual2.score(X2,y2))\n",
    "svm_dual2.plot('Non linear SVM plot for Dataset 2 usign rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T08:35:38.636042Z",
     "iopub.status.busy": "2021-02-05T08:35:38.635367Z",
     "iopub.status.idle": "2021-02-05T08:35:38.965406Z",
     "shell.execute_reply": "2021-02-05T08:35:38.966030Z"
    },
    "papermill": {
     "duration": 0.38739,
     "end_time": "2021-02-05T08:35:38.966302",
     "exception": false,
     "start_time": "2021-02-05T08:35:38.578912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# using polynomial with degree 2, because its circular\n",
    "svm_dual3 = SVM_Dual(kernel='poly', degree=2)\n",
    "svm_dual3.train(X3,y3)\n",
    "print(svm_dual3.score(X3,y3))\n",
    "svm_dual3.plot('Non linear SVM plot for Dataset 3 usign polynomial with degree 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.039456,
     "end_time": "2021-02-05T08:35:39.045527",
     "exception": false,
     "start_time": "2021-02-05T08:35:39.006071",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Working with the pre-defined SVM Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T08:35:39.139805Z",
     "iopub.status.busy": "2021-02-05T08:35:39.134722Z",
     "iopub.status.idle": "2021-02-05T08:35:39.142397Z",
     "shell.execute_reply": "2021-02-05T08:35:39.143138Z"
    },
    "papermill": {
     "duration": 0.058195,
     "end_time": "2021-02-05T08:35:39.143409",
     "exception": false,
     "start_time": "2021-02-05T08:35:39.085214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane.html\n",
    "\n",
    "# defining a function to plot decision boundary according to the svm model\n",
    "def plot(X, y, svm, title='SVM plot'):\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=plt.cm.Paired)\n",
    "\n",
    "    # plot the decision function\n",
    "    ax = plt.gca()\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "\n",
    "    # create grid to evaluate model\n",
    "    xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "    yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "    YY, XX = np.meshgrid(yy, xx)\n",
    "    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "    Z = svm.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "    # plot decision boundary and margins\n",
    "    ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5,\n",
    "               linestyles=['--', '-', '--'])\n",
    "    # plot support vectors\n",
    "    ax.scatter(svm.support_vectors_[:, 0], svm.support_vectors_[:, 1], s=100,\n",
    "               linewidth=1, facecolors='none', edgecolors='k')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T08:35:39.260086Z",
     "iopub.status.busy": "2021-02-05T08:35:39.259407Z",
     "iopub.status.idle": "2021-02-05T08:35:39.447927Z",
     "shell.execute_reply": "2021-02-05T08:35:39.447220Z"
    },
    "papermill": {
     "duration": 0.249307,
     "end_time": "2021-02-05T08:35:39.448077",
     "exception": false,
     "start_time": "2021-02-05T08:35:39.198770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for dataset 1\n",
    "# creating testing and training set\n",
    "### ENTER YOUR CODE ###\n",
    "\n",
    "# using linear kernal as our margin is a line\n",
    "# training the model\n",
    "### ENTER YOUR CODE ###\n",
    "\n",
    "# accurcy print\n",
    "print(\"Test accuracy\", accuracy_score(svm1.predict(X_test), y_test))\n",
    "print(\"Train accuracy\", accuracy_score(svm1.predict(X_train), y_train))\n",
    "\n",
    "plot(X1, y1, svm1, title='SVM plot for dataset 1 using linear kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T08:35:39.559022Z",
     "iopub.status.busy": "2021-02-05T08:35:39.539139Z",
     "iopub.status.idle": "2021-02-05T08:35:39.723748Z",
     "shell.execute_reply": "2021-02-05T08:35:39.722037Z"
    },
    "papermill": {
     "duration": 0.234535,
     "end_time": "2021-02-05T08:35:39.723918",
     "exception": false,
     "start_time": "2021-02-05T08:35:39.489383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for dataset 2\n",
    "# creating testing and training set\n",
    "### ENTER YOUR CODE ###\n",
    "\n",
    "# using rbf kernal as our margin is non linear\n",
    "### ENTER YOUR CODE ###\n",
    "# training the model\n",
    "### ENTER YOUR CODE ###\n",
    "\n",
    "# accurcy print\n",
    "print(\"Test accuracy\", accuracy_score(svm2.predict(X_test), y_test))\n",
    "print(\"Train accuracy\", accuracy_score(svm2.predict(X_train), y_train))\n",
    "plot(X2, y2, svm2, title='SVM plot for dataset 2 using rbf kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-05T08:35:39.819610Z",
     "iopub.status.busy": "2021-02-05T08:35:39.817157Z",
     "iopub.status.idle": "2021-02-05T08:35:39.977984Z",
     "shell.execute_reply": "2021-02-05T08:35:39.978692Z"
    },
    "papermill": {
     "duration": 0.21121,
     "end_time": "2021-02-05T08:35:39.978901",
     "exception": false,
     "start_time": "2021-02-05T08:35:39.767691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for dataset 3\n",
    "# creating testing and training set\n",
    "### ENTER YOUR CODE ###\n",
    "\n",
    "# using poly with degree 2 as our margin is circular\n",
    "### ENTER YOUR CODE ###\n",
    "# training the model\n",
    "### ENTER YOUR CODE ###\n",
    "\n",
    "# accurcy print\n",
    "print(\"Test accuracy\", accuracy_score(svm3.predict(X_test), y_test))\n",
    "print(\"Train accuracy\", accuracy_score(svm3.predict(X_train), y_train))\n",
    "plot(X3, y3, svm3, title='SVM plot for dataset 3 using polynomial kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.062251,
     "end_time": "2021-02-05T08:35:40.230406",
     "exception": false,
     "start_time": "2021-02-05T08:35:40.168155",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Thank you"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26.696798,
   "end_time": "2021-02-05T08:35:41.005875",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-05T08:35:14.309077",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
